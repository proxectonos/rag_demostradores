# Evaluaci√≥n con RAGAS
En esta rama presentamos una serie de scripts para llevar a cabo evaluaciones de datasets mediante [Ragas](https://docs.ragas.io/en/stable/). En nuestro caso, empleamos modelos de embeddings y modelos generativos [locales](https://docs.ragas.io/en/stable/howtos/integrations/langchain/) a trav√©s de [LangChain y HuggingFace](https://python.langchain.com/api_reference/huggingface/llms/langchain_huggingface.llms.huggingface_pipeline.HuggingFacePipeline.html#langchain_huggingface.llms.huggingface_pipeline.HuggingFacePipeline) para obtener los resultados de las m√©tricas, adem√°s de aplicar [prompts adaptados](https://docs.ragas.io/en/stable/howtos/customizations/metrics/_metrics_language_adaptation/) al espa√±ol.

## Jerarqu√≠a de archivos
* ``orig_prompts/`` ‚Üí carpeta de prompts originales aplicados por Ragas. Son archivos JSON generados a partir de aplicar una funci√≥n ``save_prompts()`` en las m√©tricas de puntuaci√≥n.

* ``prompts/`` ‚Üí carpeta de prompts traducidos por Ragas. Comparten la misma estructura que los prompts originales. En realidad, lo que est√° realmente traducido son los ejemplos que usa Ragas en las instrucciones de m√©tricas.

* ``results/`` ‚Üí carpeta de datasets evaluados. Son archivos JSONL a modo de ejemplo de resultados de evaluaci√≥n de Ragas, que en realidad es el mismo dataset que se proporciona de entrada (``dataset.jsonl``) con una columna a√±adida por cada m√©trica empleada, cuyo valor es su correspondiente puntuaci√≥n.

* ``config.yaml`` ‚Üí archivo de configuraci√≥n para los scripts. Se especifican todos los par√°metros que intervienen en el c√≥digo compartido. En el propio fichero se indican los que se deben modificar.

* ``dataset.jsonl`` ‚Üí ejemplo de dataset de entrada para aplicar evaluaci√≥n con Ragas, incluyendo los atributos necesarios a incorporar.

* ``launcher.sh`` ‚Üí script de lanzamiento para nodos de computaci√≥n. Se debe incluir la ruta del archivo de configuraci√≥n.

* ``main.py`` ‚Üí script de ejecuci√≥n principal. Inicia y configura los par√°metros principales para realizar evaluaciones mediante la clase ``RAGEvaluator``.

* ``rag_evaluator.py`` ‚Üí script de evaluaci√≥n de m√©tricas con Ragas. Entre ellas se pueden escoger:
    * [``LLMContextPrecisionWithoutReference``](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_precision/#context-precision-without-reference)
    * [``LLMContextPrecisionWithReference`` ](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_precision/#context-precision-with-reference)
    * [``LLMContextRecall``](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_recall/)
    * [``Faithfulness``](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/faithfulness/#faithfulness)
    * [``ResponseRelevancy``](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/answer_relevance/#response-relevancy)
    * [``ContextRelevance``](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/nvidia_metrics/#context-relevance)

## Flujo de ejecuci√≥n
El fichero ``launcher.sh`` ejecuta el c√≥digo ``main.py`` con la ruta del archivo de configuraci√≥n ``config.yaml``. En este archivo de configuraci√≥n **se deben modificar** rutas como la ubicaci√≥n de los modelos, la ubicaci√≥n del proyecto, la ubicaci√≥n del dataset y la ubicaci√≥n de salida de resultados. El resto de par√°metros se han mantenido por defecto con la configuraci√≥n que nos ofreci√≥ mejores resultados durante nuestros experimentos.

```
sbatch launcher.sh
```

### Carga del modelo local
En ``main.py`` se inicia una instancia de la clase ``RAGEvaluator`` (en ``rag_evaluator.py``) indicando el modelo de embeddings y el modelo generativo que se va a utilizar de manera local. Para ello, cargamos nuestros modelos localmente con HuggingFace mediante ``HuggingFacePipeline`` (consultar funci√≥n ``RAGEvaluator._get_llm()``) dado el primer caso, o bien mediante ``HuggingFaceEmbeddings`` dado el segundo (consultar funci√≥n ``RAGEvaluator._get_embeddings()``). Una vez cargados, se adec√∫an a Ragas con [LangChain](https://docs.ragas.io/en/stable/howtos/integrations/langchain/) mediante ``LangchainLLMWrapper`` y ``LangchainEmbeddingsWrapper`` respectivamente.

### Selecci√≥n y/o traducci√≥n de prompts
 A continuaci√≥n se establecen los prompts que van a intervenir en la puntuaci√≥n de las m√©tricas mediante la funci√≥n ``RAGEvaluator.set_prompts()``. Su funci√≥n es buscar dentro de la carpeta de prompts (especificada en ``config.yaml``) la existencia de los archivos predefinidos por Ragas en el mismo idioma indicado en la configuraci√≥n. Si existen dichos archivos se cargan, y si no, se generan a trav√©s de la funci√≥n ``adapt_prompts()`` de Ragas asignada a cada m√©trica particularmente.

> ‚ö†Ô∏è **ADVERTENCIA**
> La carpeta ``prompts/`` contiene ejemplos de prompts traducidos al espa√±ol con los modelos de la configuraci√≥n actual siguiendo el m√©todo establecido por Ragas. Dichas traducciones se realizaron en la versi√≥n ``ragas v0.2.15``, pero en la m√°s reciente ``ragas v0.3.6``, aplicar el mismo flujo de ejecuci√≥n nos da errores. Entendemos que se debe a la idoneidad de los modelos, puesto que Ragas espera principalmente LLMs como GPT.

> üí° **CONSEJO** 
> Dada la configuraci√≥n actual, la ejecuci√≥n funcionar√° porque en el c√≥digo se utilizar√°n los archivos de prompts que descargamos previamente. Para una experiencia personalizada en otro idioma que sea lo m√°s similar posible a una ejecuci√≥n real, recomendamos traducir manualmente los ``"examples"`` de los archivos de prompts de Ragas al idioma deseado y modificar los nombres de archivo o par√°metros de configuraci√≥n pertinentes, siempre respetando el orden y estructura actual que compartimos en este proyecto.

### Evaluaci√≥n de datasets
Si todas las configuraciones son correctas, el archivo ``dataset.jsonl`` mantiene la misma estructura y la ejecuci√≥n hasta este punto ha sucedido con normalidad, empezar√°n las evaluaciones del conjunto de datos con Ragas. Aunque existen m√©tricas en Ragas que no requieren el uso de LLMs en su puntuaci√≥n, en nuestro caso aplicamos aquellas que en las que s√≠ intervienen (como se mencion√≥ previamente). Tras esperar a que finalice la ejecuci√≥n, los resultados deber√≠an aparecer en ``results/`` o aquella carpeta de salida definida en el archivo de configuraci√≥n.

## Explicaci√≥n de m√©tricas
De entre todas las [m√©tricas disponibles](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/) en Ragas, a continuaci√≥n mostramos aquellas que consideramos m√°s significativas para la evaluaci√≥n de RAGs. Normalmente, estas m√©tricas solicitan la mayor√≠a o la totalidad de los siguientes atributos implicados en un RAG:
* ``user_input (str)``: pregunta o consulta de entrada a un RAG.
* ``response (str)``: respuesta de salida del RAG.
* ``retrieved_contexts (list)``: lista de contextos recuperados por el RAG para generar la respuesta.
* ``reference (str)``: respuesta de referencia deseable.

### Context Precision
Esta m√©trica eval√∫a no solo cu√°ntos fragmentos relevantes aparecen entre los primeros $K$ resultados, sino tambi√©n en qu√© posiciones aparecen. 
Da m√°s peso a los fragmentos relevantes que aparecen en posiciones m√°s altas, reflejando la capacidad del sistema para priorizar la informaci√≥n √∫til.

$$\text{Context Precision@K} = \frac{\sum_{k=1}^{K} \left( \text{Precision@k} \times v_k \right)}{\text{Total number of relevant items in the top } K \text{ results}}$$

* $K$: n√∫mero total de fragmentos considerados (por ejemplo, los primeros 5).
* $vk$: indicador de relevancia en la posici√≥n $k = 1$ si el fragmento en la posici√≥n $k$ es relevante, 0 si no lo es.
* $\text{Precision@k}$: la precisi√≥n calculada hasta la posici√≥n $k$.
* $\text{Denominador}$: n√∫mero total de fragmentos relevantes presentes entre los primeros $K$ resultados

Si todos los fragmentos relevantes aparecen en los primeros puestos, el valor ser√° alto. Si los fragmentos relevantes est√°n dispersos o en posiciones bajas, el valor ser√° menor. Esta m√©trica premia la aparici√≥n temprana de fragmentos relevantes y penaliza cuando estos aparecen tarde o no aparecen. En la versi√≥n [``LLMContextPrecisionWithoutReference``](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_precision/#context-precision-without-reference) se compara ``retrieved_contexts`` con ``response``, mientras que en la versi√≥n [``LLMContextPrecisionWithReference`` ](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_precision/#context-precision-with-reference) se compara ``retrieved_contexts`` con ``reference``.

$$\text{Precision@k} = {\text{true positives@k} \over  (\text{true positives@k} + \text{false positives@k})}$$
* $\text{true positives@k}$: n√∫mero de fragmentos relevantes entre los primeros $k$.
* $\text{false positives@k}$: n√∫mero de fragmentos no relevantes entre los primeros $k$.

$\text{Precision@k}$ mide la proporci√≥n de elementos relevantes entre los primeros $k$ resultados recuperados. Un valor alto indica que la mayor√≠a de los fragmentos recuperados en los primeros puestos son relevantes para la consulta.
Un valor bajo indica que hay mucho ruido o fragmentos irrelevantes entre los primeros resultados.

#### Para una consulta se obtienen 3 fragmentos cuyas relevancias son:
* Fragmento 1: Irrelevante.
* Fragmento 2: Relevante.
* Fragmento 3: Relevante.

#### Los valores de Precision@k ser√°n:
* $\text{Precision@1} = 0 / 1 = 0$ (el primero no es relevante).
* $\text{Precision@2} = 1 / 2 = 0,5$ (uno de los dos primeros es relevante).
* $\text{Precision@3} = 2 / 3 = 0,67$ (dos de los tres primeros son relevantes).

#### Para calcular Context Precision@K con k=3:
$$\text{Context Precision@3} = \frac{(0 \times v_1 = 0) + (0,5 \times v_2 = 1) + (0,67 \times v_3 = 1)}{\text{Total number of relevant items = 2}} = 0,585$$

### Context Recall
[``LLMContextRecall``](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_recall/) eval√∫a la capacidad de recuperaci√≥n completa del sistema, asegur√°ndose de que no se omita informaci√≥n importante que deber√≠a estar presente para responder correctamente a la pregunta.
Mide cu√°ntos de los fragmentos o documentos relevantes de una consulta fueron efectivamente recuperados por el sistema.

Su valor var√≠a entre 0 y 1, donde 1 significa que se recuper√≥ toda la informaci√≥n relevante y 0 que no se recuper√≥ nada relevante

$$\text{Context Recall} = \frac{\text{Number of claims in the reference supported by the retrieved context}}{\text{Total number of claims in the reference}}$$

1. El LLM divide ``reference`` en afirmaciones ($\text{claims}$).
2. Se verifica para cada $\text{claim}$ si puede ser inferida directamente de ``retrieved_contexts``.
3. Se calcula la m√©trica mediante la f√≥rmula.

#### Ejemplo

La referencia se divide en 4 claims, de las cuales tres pueden ser inferidas de los contextos y una no. En este caso:
$$\text{Context Recall} = \frac{\text{Number of claims in the reference supported by the retrieved context} = 3}{\text{Total number of claims in the reference} = 4} = 0,75$$

### Faithfulness
[``Faithfulness``](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/faithfulness/#faithfulness) eval√∫a si todas las afirmaciones de la respuesta pueden ser justificadas √∫nicamente con la informaci√≥n presente en los fragmentos recuperados, evitando as√≠ las alucinaciones o invenciones del modelo.

Mide cu√°n consistente y fiel es la respuesta generada por el sistema respecto al contexto recuperado.
El resultado es un valor entre 0 y 1, donde 1 indica que todas las afirmaciones est√°n justificadas por el contexto y 0 que ninguna lo est√°.

$$\text{Faithfulness} = \frac{\text{Number of claims in the response supported by the retrieved context}}{\text{Total number of claims in the response}}$$

1. El LLM divide ``response`` en afirmaciones ($\text{claims}$).
2. Se verifica para cada $\text{claim}$ si puede ser inferida directamente de ``retrieved_contexts``.
3. Se calcula la m√©trica mediante la f√≥rmula.

Un valor alto de $\text{Faithfulness}$ indica que la respuesta es totalmente consistente con el contexto recuperado. Sin embargo, un valor bajo indica que la respuesta contiene informaci√≥n no respaldada por el contexto, lo que puede sugerir la existencia de alucinaciones o errores factuales.

#### Ejemplo
* ``user_input``: ¬øD√≥nde y cu√°ndo naci√≥ Einstein? 
* ``retrieved_context``: Albert Einstein (nacido el 14 de marzo de 1879) fue un f√≠sico te√≥rico alem√°n. 
* ``response``: Einstein naci√≥ en Alemania el 20 de marzo de 1879.

De esta respuesta, un modelo extrae las siguientes $\text{claims}$:

1. $\text{Einstein naci√≥ en Alemania.}$ ‚Üí Esta afirmaci√≥n s√≠ se puede inferir del contexto.
2. $\text{Einstein naci√≥ el 20 de marzo de 1879.}$ ‚Üí Esta afirmaci√≥n no se puede inferir del contexto.

Con esto, podemos calcular la puntuaci√≥n de $\text{Faithfulness}$.

$$\text{Faithfulness} = \frac{\text{Number of claims in the response supported by the retrieved context}=1}{\text{Total number of claims in the response}=2} = 0,5$$

### Response Relevancy
[``ResponseRelevancy``](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/answer_relevance/#response-relevancy) eval√∫a si la respuesta aborda directamente la intenci√≥n de la pregunta, penalizando respuestas incompletas o que contienen informaci√≥n redundante o innecesaria.

Mide qu√© tan relevante es la respuesta generada respecto a la pregunta original del usuario.
Esta m√©trica no eval√∫a la veracidad de la respuesta, solo su pertinencia respecto a la pregunta.

$$\text{Answer Relevancy} = \frac{1}{N} \sum_{i=1}^{N} \text{cosine similarity}(E_{g_i}, E_o)$$

1. El LLM genera varias preguntas (por defecto 3) a partir de la respuesta.
2.  Se calcula la similitud de coseno entre el embedding de la pregunta original $E_0$ y el embedding de cada pregunta generada $E_{gi}$.
3. Se calcula la media de las similitudes de coseno mediante la f√≥rmula anterior.

Una puntuaci√≥n alta de la m√©trica indica que la respuesta es muy relevante y responde directamente a la pregunta. Por el contrario, una puntuaci√≥n baja indica que la respuesta es incompleta, irrelevante o contiene informaci√≥n innecesaria.

#### Ejemplo
* ``user_input``: ¬øD√≥nde est√° Francia y cu√°l es su capital?
    * Si la respuesta obtenida es ``response_1 = ‚ÄúFrancia est√° en Europa occidental.‚Äù`` deber√≠a devolver una puntuaci√≥n m√°s baja.
    * Si la respuesta obtenida es ``response_2 = ‚ÄúFrancia est√° en Europa occidental y su capital es Par√≠s.‚Äù`` deber√≠a devolver una puntuaci√≥n m√°s alta.

### Context Relevance
[``ContextRelevance``](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/nvidia_metrics/#context-relevance) eval√∫a, mediante el razonamiento de un LLM, hasta qu√© punto los fragmentos de contexto recuperados (``retrieved_contexts``) son relevantes para responder a una pregunta de usuario (``user_input``). Dos prompts predeterminados est√°n implicados en el c√°lculo de la m√©trica.

1. ``template_relevance1`` ‚Üí "### Instructions\n\n"
"You are a world class expert designed to evaluate the relevance score of a Context"
" in order to answer the Question.\n"
"Your task is to determine if the Context contains proper information to answer the Question.\n"
"Do not rely on your previous knowledge about the Question.\n"
"Use only what is written in the Context and in the Question.\n"
"Follow the instructions below:\n"
"0. If the context does not contains any relevant information to answer the question, say 0.\n"
"1. If the context partially contains relevant information to answer the question, say 1.\n"
"2. If the context contains any relevant information to answer the question, say 2.\n"
"You must provide the relevance score of 0, 1, or 2, nothing else.\nDo not explain.\n"
"### Question: {query}\n\n"
"### Context: {context}\n\n"
"Do not try to explain.\n"
"Analyzing Context and Question, the Relevance score is "

2. ``template_relevance2`` ‚Üí "As a specially designed expert to assess the relevance score of a given Context in relation to a Question, "
"my task is to determine the extent to which the Context provides information necessary to answer the Question. "
"I will rely solely on the information provided in the Context and Question, and not on any prior knowledge.\n\n"
"Here are the instructions I will follow:\n"
"* If the Context does not contain any relevant information to answer the Question, I will respond with a relevance score of 0.\n"
"* If the Context partially contains relevant information to answer the Question, I will respond with a relevance score of 1.\n"
"* If the Context contains any relevant information to answer the Question, I will respond with a relevance score of 2.\n\n"
"### Question: {query}\n\n"
"### Context: {context}\n\n"
"Do not try to explain.\n"
"Based on the provided Question and Context, the Relevance score is  ["

El LLM recibe el prompt ``template_relevance1`` que contiene ``user_input`` y ``retrieved_contexts`` incrustados, junto con instrucciones claras para puntuar la relevancia del contexto con tres opciones:

* 0 ‚Üí el contexto no es relevante para la pregunta.
* 1 ‚Üí parcialmente relevante.
* 2 ‚Üí completamente relevante.

La puntuaci√≥n final se normaliza en el rango $[0, 1.0]$ y se promedia sobre dos ejecuciones del LLM para mayor robustez. Si alguna ejecuci√≥n falla o da una salida inv√°lida, se reintenta hasta 5 veces por defecto. En casos l√≠mite (como cuando el contexto est√° vac√≠o o es id√©ntico a la pregunta), la puntuaci√≥n se fuerza a 0 directamente.

#### Ejemplo
* ``user_input``: "When and Where Albert Einstein was born?"
* ``retrieved_contexts``: ["Albert Einstein was born March 14, 1879.", "Albert Einstein was born at Ulm, in W√ºrttemberg, Germany."]

Al LLM se le solicitan dos plantillas distintas (``template_relevance1`` y ``template_relevance2``) para evaluar la relevancia de los contextos recuperados en relaci√≥n con la consulta del usuario. Cada pregunta devuelve una valoraci√≥n de relevancia de 0, 1 o 2.

Cada valoraci√≥n se normaliza a una escala $[0, 1.0]$ dividi√©ndola por 2. Si ambas valoraciones son v√°lidas, la puntuaci√≥n final es la media de estos valores normalizados; si s√≥lo una es v√°lida, se utiliza esa puntuaci√≥n.

En este ejemplo, los dos contextos recuperados responden plenamente a la consulta del usuario, ya que proporcionan tanto la fecha de nacimiento como el lugar de nacimiento de Albert Einstein. Por lo tanto, ambas preguntas puntuar√≠an los contextos combinados con 2 (totalmente relevantes). Al normalizar cada puntuaci√≥n se obtiene $2 / 2 = 1.0$, y al promediar los dos resultados se mantiene la puntuaci√≥n final en $1.0$.
